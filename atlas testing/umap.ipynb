{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published_date</th>\n",
       "      <th>published_platform</th>\n",
       "      <th>rating</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-12T14:41:14-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>1</td>\n",
       "      <td>review</td>\n",
       "      <td>We used this airline to go from Singapore to L...</td>\n",
       "      <td>Ok</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-11T19:39:13-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>The service on Singapore Airlines Suites Class...</td>\n",
       "      <td>The service in Suites Class makes one feel lik...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-11T12:20:23-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>0</td>\n",
       "      <td>review</td>\n",
       "      <td>Booked, paid and received email confirmation f...</td>\n",
       "      <td>Don’t give them your money</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-11T07:12:27-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>Best airline in the world, seats, food, servic...</td>\n",
       "      <td>Best Airline in the World</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-10T05:34:18-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>0</td>\n",
       "      <td>review</td>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2018-08-06T03:48:21-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>First part done with Singapore Airlines - acce...</td>\n",
       "      <td>Flew to NZ 1st half Singapore Airlines, 2nd ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2018-08-05T22:50:29-04:00</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>And again a great Flight with Singapore Air. G...</td>\n",
       "      <td>Best Airline</td>\n",
       "      <td>1</td>\n",
       "      <td>9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2018-08-05T22:47:06-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>We flew business class from Frankfurt, via Sin...</td>\n",
       "      <td>Superb service on Singapore Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2018-08-05T20:32:03-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>As always, the A380 aircraft was spotlessly pr...</td>\n",
       "      <td>A Comfortable Fiight Spoiled by lack of adequa...</td>\n",
       "      <td>2</td>\n",
       "      <td>9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2018-08-05T20:19:51-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>As always, Singapore Airlines has done it agai...</td>\n",
       "      <td>Delivered as expected :)</td>\n",
       "      <td>3</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 published_date published_platform  rating    type  \\\n",
       "0     2024-03-12T14:41:14-04:00            Desktop       1  review   \n",
       "1     2024-03-11T19:39:13-04:00            Desktop       2  review   \n",
       "2     2024-03-11T12:20:23-04:00            Desktop       0  review   \n",
       "3     2024-03-11T07:12:27-04:00            Desktop       2  review   \n",
       "4     2024-03-10T05:34:18-04:00            Desktop       0  review   \n",
       "...                         ...                ...     ...     ...   \n",
       "9995  2018-08-06T03:48:21-04:00            Desktop       2  review   \n",
       "9996  2018-08-05T22:50:29-04:00             Mobile       2  review   \n",
       "9997  2018-08-05T22:47:06-04:00            Desktop       2  review   \n",
       "9998  2018-08-05T20:32:03-04:00            Desktop       2  review   \n",
       "9999  2018-08-05T20:19:51-04:00            Desktop       2  review   \n",
       "\n",
       "                                                   text  \\\n",
       "0     We used this airline to go from Singapore to L...   \n",
       "1     The service on Singapore Airlines Suites Class...   \n",
       "2     Booked, paid and received email confirmation f...   \n",
       "3     Best airline in the world, seats, food, servic...   \n",
       "4     Premium Economy Seating on Singapore Airlines ...   \n",
       "...                                                 ...   \n",
       "9995  First part done with Singapore Airlines - acce...   \n",
       "9996  And again a great Flight with Singapore Air. G...   \n",
       "9997  We flew business class from Frankfurt, via Sin...   \n",
       "9998  As always, the A380 aircraft was spotlessly pr...   \n",
       "9999  As always, Singapore Airlines has done it agai...   \n",
       "\n",
       "                                                  title  helpful_votes    id  \n",
       "0                                                    Ok              0     0  \n",
       "1     The service in Suites Class makes one feel lik...              0     1  \n",
       "2                            Don’t give them your money              0     2  \n",
       "3                             Best Airline in the World              0     3  \n",
       "4     Premium Economy Seating on Singapore Airlines ...              0     4  \n",
       "...                                                 ...            ...   ...  \n",
       "9995  Flew to NZ 1st half Singapore Airlines, 2nd ha...              1  9995  \n",
       "9996                                       Best Airline              1  9996  \n",
       "9997               Superb service on Singapore Airlines              1  9997  \n",
       "9998  A Comfortable Fiight Spoiled by lack of adequa...              2  9998  \n",
       "9999                           Delivered as expected :)              3  9999  \n",
       "\n",
       "[10000 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/max/Downloads/airlines_reviews.csv\")\n",
    "df['id'] = df.index\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-10 18:50:56.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m867\u001b[0m - \u001b[1mOrganization name: `nomic`\u001b[0m\n",
      "\u001b[32m2025-05-10 18:50:56.958\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m895\u001b[0m - \u001b[1mCreating dataset `airlines-reviews`\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from nomic import AtlasDataset\n",
    "\n",
    "dataset = AtlasDataset(\"airlines_reviews\", unique_id_field=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-10 18:51:47.153\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_validate_and_correct_arrow_upload\u001b[0m:\u001b[36m334\u001b[0m - \u001b[33m\u001b[1mReplacing 1 null values for field title with string 'null'. This behavior will change in a future version.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-10 18:51:47.155\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_validate_and_correct_arrow_upload\u001b[0m:\u001b[36m357\u001b[0m - \u001b[33m\u001b[1mid_field is not a string. Converting to string from int32\u001b[0m\n",
      "100%|██████████| 2/2 [00:40<00:00, 20.41s/it]\n",
      "\u001b[32m2025-05-10 18:52:28.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_add_data\u001b[0m:\u001b[36m1714\u001b[0m - \u001b[1mUpload succeeded.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset.add_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-10 18:56:04.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36mcreate_index\u001b[0m:\u001b[36m1301\u001b[0m - \u001b[1mCreated map `0196bc69-9bf0-7ce2-5af7-55dab8bb5ead` in dataset `nomic/airlines-reviews`: https://atlas.nomic.ai/data/nomic/airlines-reviews\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Atlas Projection 0196bc69-9bf0-7ce2-5af7-55dab8bb5ead. Status Building Map. <a target=\"_blank\" href=\"https://atlas.nomic.ai/data/nomic/airlines-reviews/map\">view online</a>"
      ],
      "text/plain": [
       "0196bc69-9bf0-7ce2-5af7-55dab8bb5ead: https://atlas.nomic.ai/data/nomic/airlines-reviews"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.create_index(\n",
    "    indexed_field='text',\n",
    "    projection='umap'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published_date</th>\n",
       "      <th>published_platform</th>\n",
       "      <th>rating</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>helpful_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-12T14:41:14-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>1</td>\n",
       "      <td>review</td>\n",
       "      <td>We used this airline to go from Singapore to L...</td>\n",
       "      <td>Ok</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-11T19:39:13-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>The service on Singapore Airlines Suites Class...</td>\n",
       "      <td>The service in Suites Class makes one feel lik...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-11T12:20:23-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>0</td>\n",
       "      <td>review</td>\n",
       "      <td>Booked, paid and received email confirmation f...</td>\n",
       "      <td>Don’t give them your money</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-11T07:12:27-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>Best airline in the world, seats, food, servic...</td>\n",
       "      <td>Best Airline in the World</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-10T05:34:18-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>0</td>\n",
       "      <td>review</td>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2018-08-06T03:48:21-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>First part done with Singapore Airlines - acce...</td>\n",
       "      <td>Flew to NZ 1st half Singapore Airlines, 2nd ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2018-08-05T22:50:29-04:00</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>And again a great Flight with Singapore Air. G...</td>\n",
       "      <td>Best Airline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2018-08-05T22:47:06-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>We flew business class from Frankfurt, via Sin...</td>\n",
       "      <td>Superb service on Singapore Airlines</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2018-08-05T20:32:03-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>As always, the A380 aircraft was spotlessly pr...</td>\n",
       "      <td>A Comfortable Fiight Spoiled by lack of adequa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2018-08-05T20:19:51-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>As always, Singapore Airlines has done it agai...</td>\n",
       "      <td>Delivered as expected :)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 published_date published_platform  rating    type  \\\n",
       "0     2024-03-12T14:41:14-04:00            Desktop       1  review   \n",
       "1     2024-03-11T19:39:13-04:00            Desktop       2  review   \n",
       "2     2024-03-11T12:20:23-04:00            Desktop       0  review   \n",
       "3     2024-03-11T07:12:27-04:00            Desktop       2  review   \n",
       "4     2024-03-10T05:34:18-04:00            Desktop       0  review   \n",
       "...                         ...                ...     ...     ...   \n",
       "9995  2018-08-06T03:48:21-04:00            Desktop       2  review   \n",
       "9996  2018-08-05T22:50:29-04:00             Mobile       2  review   \n",
       "9997  2018-08-05T22:47:06-04:00            Desktop       2  review   \n",
       "9998  2018-08-05T20:32:03-04:00            Desktop       2  review   \n",
       "9999  2018-08-05T20:19:51-04:00            Desktop       2  review   \n",
       "\n",
       "                                                   text  \\\n",
       "0     We used this airline to go from Singapore to L...   \n",
       "1     The service on Singapore Airlines Suites Class...   \n",
       "2     Booked, paid and received email confirmation f...   \n",
       "3     Best airline in the world, seats, food, servic...   \n",
       "4     Premium Economy Seating on Singapore Airlines ...   \n",
       "...                                                 ...   \n",
       "9995  First part done with Singapore Airlines - acce...   \n",
       "9996  And again a great Flight with Singapore Air. G...   \n",
       "9997  We flew business class from Frankfurt, via Sin...   \n",
       "9998  As always, the A380 aircraft was spotlessly pr...   \n",
       "9999  As always, Singapore Airlines has done it agai...   \n",
       "\n",
       "                                                  title  helpful_votes  \n",
       "0                                                    Ok              0  \n",
       "1     The service in Suites Class makes one feel lik...              0  \n",
       "2                            Don’t give them your money              0  \n",
       "3                             Best Airline in the World              0  \n",
       "4     Premium Economy Seating on Singapore Airlines ...              0  \n",
       "...                                                 ...            ...  \n",
       "9995  Flew to NZ 1st half Singapore Airlines, 2nd ha...              1  \n",
       "9996                                       Best Airline              1  \n",
       "9997               Superb service on Singapore Airlines              1  \n",
       "9998  A Comfortable Fiight Spoiled by lack of adequa...              2  \n",
       "9999                           Delivered as expected :)              3  \n",
       "\n",
       "[10000 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"https://docs.nomic.ai/singapore_airlines_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomic import AtlasDataset\n",
    "from nomic.data_inference import ProjectionOptions\n",
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "df = pd.read_csv(\"https://docs.nomic.ai/singapore_airlines_reviews.csv\")\n",
    "\n",
    "dataset = AtlasDataset(\"airline-reviews\")\n",
    "\n",
    "dataset.add_data(df)\n",
    "\n",
    "atlas_map = dataset.create_index(\n",
    "    indexed_field='text',\n",
    "    projection=ProjectionOptions(\n",
    "      model=\"umap\",\n",
    "      n_neighbors=20,\n",
    "      min_dist=0.01,\n",
    "      n_epochs=200\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for image to HTML conversion\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "# --- Helper Function to Convert PIL Image to HTML IMG Tag ---\n",
    "def pil_to_img_tag(image: Image.Image, format=\"PNG\") -> str:\n",
    "    \"\"\"Converts a PIL image to an img tag with the image in base64\"\"\"\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format=format)\n",
    "    base64_data = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "    # Added style for consistent image size in Atlas UI\n",
    "    return f\"<img src='data:image/{format.lower()};base64,{base64_data}' alt='Embedded Image' style='width:28px; height:28px;'>\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First approach, train a UMAP on all embeddings from all epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from nomic import AtlasDataset\n",
    "import time\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "NUM_EPOCHS = 15\n",
    "LEARNING_RATE = 3e-6\n",
    "BATCH_SIZE = 128\n",
    "NUM_VIS_SAMPLES = 5000\n",
    "EMBEDDING_DIM = 128\n",
    "ATLAS_DATASET_NAME = \"mnist_cnn_epoch_embeddings_viz\"\n",
    "\n",
    "# Determine device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "print(f\"Using device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 60000 samples, visualizing 5000 test samples per epoch.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 1. Define PyTorch Model ---\n",
    "class MNIST_CNN(nn.Module):\n",
    "    def __init__(self, embedding_dim=128):\n",
    "        super(MNIST_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # 28x28 -> 14x14\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # 14x14 -> 7x7\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, embedding_dim) # Embedding layer\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(embedding_dim, 10) # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        embeddings = self.relu3(self.fc1(x))\n",
    "        output = self.fc2(embeddings)\n",
    "        return output, embeddings\n",
    "\n",
    "# --- 2. Load MNIST Data ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# DataLoader for training\n",
    "# Handle persistent_workers based on device type (MPS doesn't support it well)\n",
    "persistent_workers_flag = True if device.type not in ['mps', 'cpu'] else False\n",
    "num_workers_val = 2 if persistent_workers_flag else 0 # num_workers > 0 can cause issues on MPS without persistent_workers\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers_val, persistent_workers=persistent_workers_flag if num_workers_val > 0 else False)\n",
    "\n",
    "# Create a subset of the test dataset for visualization\n",
    "vis_indices = list(range(NUM_VIS_SAMPLES))\n",
    "vis_subset = Subset(test_dataset, vis_indices)\n",
    "test_loader_for_vis = DataLoader(vis_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers_val, persistent_workers=persistent_workers_flag if num_workers_val > 0 else False)\n",
    "\n",
    "print(f\"Training on {len(train_dataset)} samples, visualizing {NUM_VIS_SAMPLES} test samples per epoch.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Batch [200/469], Avg Loss: 2.2662\n",
      "Epoch [1/15], Batch [400/469], Avg Loss: 2.1666\n",
      "Epoch 1/15 training finished in 6.11s.\n",
      "\n",
      "Collected 5000 embeddings for visualization in epoch 1.\n",
      "\n",
      "Epoch [2/15], Batch [200/469], Avg Loss: 1.9643\n",
      "Epoch [2/15], Batch [400/469], Avg Loss: 1.7725\n",
      "Epoch 2/15 training finished in 5.82s.\n",
      "\n",
      "Collected 5000 embeddings for visualization in epoch 2.\n",
      "\n",
      "Epoch [3/15], Batch [200/469], Avg Loss: 1.5001\n",
      "Epoch [3/15], Batch [400/469], Avg Loss: 1.3126\n",
      "Epoch 3/15 training finished in 5.88s.\n",
      "\n",
      "Collected 5000 embeddings for visualization in epoch 3.\n",
      "\n",
      "Epoch [4/15], Batch [200/469], Avg Loss: 1.0932\n",
      "Epoch [4/15], Batch [400/469], Avg Loss: 0.9671\n",
      "Epoch 4/15 training finished in 5.95s.\n",
      "\n",
      "Collected 5000 embeddings for visualization in epoch 4.\n",
      "\n",
      "Epoch [5/15], Batch [200/469], Avg Loss: 0.8254\n",
      "Epoch [5/15], Batch [400/469], Avg Loss: 0.7588\n",
      "Epoch 5/15 training finished in 5.90s.\n",
      "\n",
      "Collected 5000 embeddings for visualization in epoch 5.\n",
      "\n",
      "Epoch [6/15], Batch [200/469], Avg Loss: 0.6701\n",
      "Epoch [6/15], Batch [400/469], Avg Loss: 0.6167\n",
      "Epoch 6/15 training finished in 6.01s.\n",
      "\n",
      "Collected 5000 embeddings for visualization in epoch 6.\n",
      "\n",
      "Epoch [7/15], Batch [200/469], Avg Loss: 0.5627\n",
      "Epoch [7/15], Batch [400/469], Avg Loss: 0.5377\n",
      "Epoch 7/15 training finished in 5.73s.\n",
      "\n",
      "Collected 5000 embeddings for visualization in epoch 7.\n",
      "\n",
      "Epoch [8/15], Batch [200/469], Avg Loss: 0.4951\n",
      "Epoch [8/15], Batch [400/469], Avg Loss: 0.4723\n",
      "Epoch 8/15 training finished in 5.87s.\n",
      "\n",
      "Collected 5000 embeddings for visualization in epoch 8.\n",
      "\n",
      "Epoch [9/15], Batch [200/469], Avg Loss: 0.4391\n",
      "Epoch [9/15], Batch [400/469], Avg Loss: 0.4290\n",
      "Epoch 9/15 training finished in 5.89s.\n",
      "\n",
      "Collected 5000 embeddings for visualization in epoch 9.\n",
      "\n",
      "Epoch [10/15], Batch [200/469], Avg Loss: 0.4066\n",
      "Epoch [10/15], Batch [400/469], Avg Loss: 0.3880\n",
      "Epoch 10/15 training finished in 6.07s.\n",
      "\n",
      "Collected 5000 embeddings for visualization in epoch 10.\n",
      "\n",
      "Epoch [11/15], Batch [200/469], Avg Loss: 0.3714\n",
      "Epoch [11/15], Batch [400/469], Avg Loss: 0.3645\n",
      "Epoch 11/15 training finished in 5.91s.\n",
      "\n",
      "Collected 5000 embeddings for visualization in epoch 11.\n",
      "\n",
      "Epoch [12/15], Batch [200/469], Avg Loss: 0.3501\n",
      "Epoch [12/15], Batch [400/469], Avg Loss: 0.3380\n",
      "Epoch 12/15 training finished in 5.93s.\n",
      "\n",
      "Collected 5000 embeddings for visualization in epoch 12.\n",
      "\n",
      "Epoch [13/15], Batch [200/469], Avg Loss: 0.3281\n",
      "Epoch [13/15], Batch [400/469], Avg Loss: 0.3189\n",
      "Epoch 13/15 training finished in 6.02s.\n",
      "\n",
      "Collected 5000 embeddings for visualization in epoch 13.\n",
      "\n",
      "Epoch [14/15], Batch [200/469], Avg Loss: 0.3052\n",
      "Epoch [14/15], Batch [400/469], Avg Loss: 0.3025\n",
      "Epoch 14/15 training finished in 5.82s.\n",
      "\n",
      "Collected 5000 embeddings for visualization in epoch 14.\n",
      "\n",
      "Epoch [15/15], Batch [200/469], Avg Loss: 0.2913\n",
      "Epoch [15/15], Batch [400/469], Avg Loss: 0.2911\n",
      "Epoch 15/15 training finished in 5.91s.\n",
      "\n",
      "Collected 5000 embeddings for visualization in epoch 15.\n",
      "\n",
      "Total training and embedding extraction time: 132.61s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "# --- 3. Initialize Model, Optimizer, Criterion ---\n",
    "model = MNIST_CNN(embedding_dim=EMBEDDING_DIM).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# --- 4. Training Loop & Embedding Extraction ---\n",
    "all_embeddings_list = []\n",
    "all_metadata_list = []\n",
    "all_images_html = []  # Store HTML representations of images\n",
    "\n",
    "# Helper function to convert tensor to HTML image\n",
    "def tensor_to_html(tensor):\n",
    "    # Denormalize the image\n",
    "    img = tensor.clone().detach().cpu().squeeze(0)\n",
    "    img = img * 0.3081 + 0.1307  # Reverse the normalization\n",
    "    img = torch.clamp(img, 0, 1)\n",
    "\n",
    "    \n",
    "    img_pil = Image.fromarray((img.numpy() * 255).astype('uint8'), mode='L')\n",
    "    buffered = io.BytesIO()\n",
    "    img_pil.save(buffered, format=\"PNG\")\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode()\n",
    "    \n",
    "    return f'<img src=\"data:image/png;base64,{img_str}\" width=\"28\" height=\"28\">'\n",
    "\n",
    "overall_start_time = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if (batch_idx + 1) % 200 == 0: # Print every 200 mini-batches\n",
    "            print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Batch [{batch_idx+1}/{len(train_loader)}], Avg Loss: {running_loss / 200:.4f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} training finished in {time.time() - epoch_start_time:.2f}s.\\n\")\n",
    "\n",
    "    # Extract embeddings for visualization subset\n",
    "    model.eval()\n",
    "    vis_samples_collected_this_epoch = 0\n",
    "    image_offset_in_vis_subset = 0 # Tracks the index within the vis_subset (0 to NUM_VIS_SAMPLES-1)\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader_for_vis:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            _, embeddings_batch = model(data)\n",
    "            for i in range(embeddings_batch.size(0)):\n",
    "                # original_idx_in_subset is the true index of this image within the NUM_VIS_SAMPLES selected for visualization\n",
    "                original_idx_in_subset = image_offset_in_vis_subset + i \n",
    "                if original_idx_in_subset >= NUM_VIS_SAMPLES: # Should not happen if test_loader_for_vis is setup correctly\n",
    "                    continue\n",
    "                \n",
    "                all_embeddings_list.append(embeddings_batch[i].cpu().numpy())\n",
    "                \n",
    "                # Generate HTML representation of the image\n",
    "                img_html = tensor_to_html(data[i])\n",
    "                all_images_html.append(img_html)\n",
    "                \n",
    "                all_metadata_list.append({\n",
    "                    'id': f'vis_img_{original_idx_in_subset}_epoch_{epoch}', # Unique ID for Atlas\n",
    "                    'epoch': epoch,\n",
    "                    'label': f'Digit: {target[i].item()}',\n",
    "                    'vis_sample_idx': original_idx_in_subset, # Index within the 0..NUM_VIS_SAMPLES-1 range\n",
    "                    'image_html': img_html  # Add the HTML representation to metadata\n",
    "                })\n",
    "                vis_samples_collected_this_epoch += 1\n",
    "            image_offset_in_vis_subset += embeddings_batch.size(0) # Move offset by batch size\n",
    "            if vis_samples_collected_this_epoch >= NUM_VIS_SAMPLES: # Ensure we don't collect more than needed\n",
    "                break\n",
    "                \n",
    "    print(f\"Collected {vis_samples_collected_this_epoch} embeddings for visualization in epoch {epoch+1}.\\n\")\n",
    "\n",
    "total_script_time = time.time() - overall_start_time\n",
    "print(f\"Total training and embedding extraction time: {total_script_time:.2f}s\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'vis_img_0_epoch_0',\n",
       " 'epoch': 0,\n",
       " 'label': 'Digit: 7',\n",
       " 'vis_sample_idx': 0,\n",
       " 'image_html': '<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAxElEQVR4nGNgGDaAEUKFpD77sfTFHeyS9xQYGBg+X4EKPu06w8DAwMDAAuGm6l3XNHKwfCzLwPDntSTDozPIOhkYGBgYBA1PmzEw/Lh1TTh7Oi5nBP+9KIRLTuzl/2AokwlDMlv0/U1cGq1//LPDJcfQ+m83Cy45jrM/rHBqrP23Daec9+8PFrjkhO/+W4ZLjun0v9vKuCTV/v3zxSUnf/9fEU7XtP77Z4JLzvYTuiRS2FrzMNz9giKJElQXnd/htBMDAABhpTyHhRcQ2gAAAABJRU5ErkJggg==\" width=\"28\" height=\"28\">'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metadata_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings array for Atlas: (75000, 128)\n",
      "\n",
      "Length of metadata for Atlas: 75000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "atlas_embeddings_np = np.array(all_embeddings_list)\n",
    "print(f\"Shape of embeddings array for Atlas: {atlas_embeddings_np.shape}\\n\")\n",
    "print(f\"Length of metadata for Atlas: {len(all_metadata_list)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 13:57:35.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m867\u001b[0m - \u001b[1mOrganization name: `nomic`\u001b[0m\n",
      "\u001b[32m2025-05-11 13:57:36.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m895\u001b[0m - \u001b[1mCreating dataset `mnist-training-embeddings`\u001b[0m\n",
      "100%|██████████| 15/15 [00:25<00:00,  1.69s/it]\n",
      "\u001b[32m2025-05-11 13:58:02.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_add_data\u001b[0m:\u001b[36m1702\u001b[0m - \u001b[1mUpload succeeded.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset = AtlasDataset(\"mnist-training-embeddings\", unique_id_field='id')\n",
    "dataset.add_data(data=all_metadata_list, embeddings=atlas_embeddings_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 13:58:03.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36mcreate_index\u001b[0m:\u001b[36m1289\u001b[0m - \u001b[1mCreated map `0196c07f-2f63-de45-fa27-81bb42244989` in dataset `nomic/mnist-training-embeddings`: https://atlas.nomic.ai/data/nomic/mnist-training-embeddings\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Atlas Projection 0196c07f-2f63-de45-fa27-81bb42244989. Status Building Map. <a target=\"_blank\" href=\"https://atlas.nomic.ai/data/nomic/mnist-training-embeddings/map\">view online</a>"
      ],
      "text/plain": [
       "0196c07f-2f63-de45-fa27-81bb42244989: https://atlas.nomic.ai/data/nomic/mnist-training-embeddings"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.create_index(projection='umap', topic_model=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second approach, build umap every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "\n",
      "Training on 60000 samples, visualizing 100 test samples per epoch.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from nomic import AtlasDataset\n",
    "import time\n",
    "import pandas as pd # For handling map data\n",
    "\n",
    "\n",
    "\n",
    "# --- Helper Function to Wait for Projection ---\n",
    "def _wait_for_projection_completion(projection, timeout_seconds=900):\n",
    "    \"\"\"Polls the projection status until it's 'Done' or timeout.\"\"\"\n",
    "    start_time = time.time()\n",
    "    printed_waiting = False\n",
    "    final_status = \"Unknown\"\n",
    "    while True:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time > timeout_seconds:\n",
    "            try:\n",
    "                last_status_data = projection._status\n",
    "                final_status = (\n",
    "                    last_status_data.get(\"index_build_stage\")\n",
    "                    or last_status_data.get(\"job_state\")\n",
    "                    or \"ErrorFetchingStatusField\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                final_status = f\"ErrorFetchingStatusOnTimeout: {e}\"\n",
    "            raise TimeoutError(\n",
    "                f\"Timed out waiting for projection {projection.id} to complete after {timeout_seconds} seconds. Last status: {final_status}\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            status_data = projection._status\n",
    "            build_stage = status_data.get(\"index_build_stage\")\n",
    "            if build_stage is None:\n",
    "                build_stage = status_data.get(\"job_state\")\n",
    "            final_status = build_stage\n",
    "\n",
    "            if build_stage == \"Done\" or build_stage == \"Completed\":\n",
    "                total_time = time.time() - start_time\n",
    "                print(f\"Projection {projection.id} completed in {total_time:.2f} seconds.\")\n",
    "                return\n",
    "            else:\n",
    "                if not printed_waiting:\n",
    "                    print(f\"Waiting for projection {projection.id} to complete. Current status: {build_stage}\")\n",
    "                    printed_waiting = True\n",
    "                time.sleep(15)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching status for projection {projection.id}: {e}. Retrying...\")\n",
    "            if not printed_waiting:\n",
    "                printed_waiting = True\n",
    "            time.sleep(15)\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "NUM_EPOCHS = 3\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "NUM_VIS_SAMPLES = 100\n",
    "EMBEDDING_DIM = 64\n",
    "MAIN_ATLAS_DATASET_NAME = \"mnist_epoch_layouts_with_images_v3\" # Incremented version\n",
    "TEMP_DATASET_PREFIX = \"mnist_temp_img_layout_v3\" # Incremented version\n",
    "\n",
    "# Determine device\n",
    "device = torch.device(\"mps\")\n",
    "print(f\"Using device: {device}\\n\")\n",
    "\n",
    "# --- 1. Define PyTorch Model ---\n",
    "class MNIST_CNN(nn.Module):\n",
    "    def __init__(self, embedding_dim=EMBEDDING_DIM): # Use EMBEDDING_DIM from HPs\n",
    "        super(MNIST_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, embedding_dim)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(embedding_dim, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        embeddings = self.relu3(self.fc1(x))\n",
    "        output = self.fc2(embeddings)\n",
    "        return output, embeddings\n",
    "\n",
    "# --- 2. Load MNIST Data ---\n",
    "mnist_mean = (0.1307,)\n",
    "mnist_std = (0.3081,)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mnist_mean, mnist_std)\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "persistent_workers_flag = True if device.type not in ['mps', 'cpu'] else False\n",
    "num_workers_val = 2 if persistent_workers_flag else 0\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers_val, persistent_workers=persistent_workers_flag if num_workers_val > 0 else False)\n",
    "vis_indices = list(range(NUM_VIS_SAMPLES))\n",
    "vis_subset = Subset(test_dataset, vis_indices)\n",
    "test_loader_for_vis = DataLoader(vis_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers_val, persistent_workers=persistent_workers_flag if num_workers_val > 0 else False)\n",
    "print(f\"Training on {len(train_dataset)} samples, visualizing {NUM_VIS_SAMPLES} test samples per epoch.\\n\")\n",
    "\n",
    "# --- 3. Initialize Model, Optimizer, Criterion & Collectors ---\n",
    "model = MNIST_CNN(embedding_dim=EMBEDDING_DIM).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "all_epoch_embeddings_collected = []\n",
    "all_epoch_metadata_collected = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Epoch 1/3 ---\n",
      "  Epoch [1/3], Batch [200/469], Avg Loss: 0.0433\n",
      "  Epoch [1/3], Batch [400/469], Avg Loss: 0.0475\n",
      "Epoch 1 training finished in 5.20s.\n",
      "\n",
      "Collected 100 raw embeddings and images for epoch 0.\n",
      "Creating temporary Atlas dataset: mnist_temp_img_layout_v3_epoch_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 13:36:59.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m867\u001b[0m - \u001b[1mOrganization name: `nomic`\u001b[0m\n",
      "\u001b[32m2025-05-11 13:37:00.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m895\u001b[0m - \u001b[1mCreating dataset `mnist-temp-img-layout-v3-epoch-0`\u001b[0m\n",
      "1it [00:00,  1.74it/s]\n",
      "\u001b[32m2025-05-11 13:37:01.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_add_data\u001b[0m:\u001b[36m1702\u001b[0m - \u001b[1mUpload succeeded.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added data to mnist_temp_img_layout_v3_epoch_0. Creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 13:37:02.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36mcreate_index\u001b[0m:\u001b[36m1289\u001b[0m - \u001b[1mCreated map `0196c06b-f110-fdf5-ebff-8318e0ac8aa9` in dataset `nomic/mnist-temp-img-layout-v3-epoch-0`: https://atlas.nomic.ai/data/nomic/mnist-temp-img-layout-v3-epoch-0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for projection a9002090-deff-47b2-882b-b99568c66055 to complete. Current status: Building Map\n",
      "Projection a9002090-deff-47b2-882b-b99568c66055 completed in 61.54 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 13:38:04.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36m_download_projected\u001b[0m:\u001b[36m538\u001b[0m - \u001b[1mDownloading projected embeddings\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00, 1916.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1451.32it/s]\n",
      "\u001b[32m2025-05-11 13:38:06.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36mtb\u001b[0m:\u001b[36m479\u001b[0m - \u001b[1mLoading projected embeddings\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00, 507.36it/s]\n",
      "\u001b[32m2025-05-11 13:38:06.647\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36mdf\u001b[0m:\u001b[36m923\u001b[0m - \u001b[33m\u001b[1mConverting to pandas dataframe. This may materialize a large amount of data into memory.\u001b[0m\n",
      "\u001b[32m2025-05-11 13:38:06.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36m_download_data\u001b[0m:\u001b[36m902\u001b[0m - \u001b[1mDownloading data\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00, 1747.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 599.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1248.30it/s]\n",
      "\u001b[32m2025-05-11 13:38:07.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m872\u001b[0m - \u001b[1mLoading data\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00, 395.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 100 projected coordinates for epoch 0.\n",
      "DataFrame rows in temp map: 100. Metadata items for this epoch: 100.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 13:38:07.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36mdelete\u001b[0m:\u001b[36m833\u001b[0m - \u001b[1mDeleting dataset `mnist-temp-img-layout-v3-epoch-0` from organization `nomic`\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 UMAP processing complete. Added 100 points with positions and images.\n",
      "Deleting temporary dataset: mnist_temp_img_layout_v3_epoch_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 13:38:08.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36mdelete\u001b[0m:\u001b[36m833\u001b[0m - \u001b[1mDeleting dataset `mnist-temp-img-layout-v3-epoch-0` from organization `nomic`\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporary dataset mnist_temp_img_layout_v3_epoch_0 deleted.\n",
      "--- Starting Epoch 2/3 ---\n",
      "  Epoch [2/3], Batch [200/469], Avg Loss: 0.0325\n",
      "  Epoch [2/3], Batch [400/469], Avg Loss: 0.0340\n",
      "Epoch 2 training finished in 4.93s.\n",
      "\n",
      "Collected 100 raw embeddings and images for epoch 1.\n",
      "Creating temporary Atlas dataset: mnist_temp_img_layout_v3_epoch_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 13:38:14.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m867\u001b[0m - \u001b[1mOrganization name: `nomic`\u001b[0m\n",
      "\u001b[32m2025-05-11 13:38:15.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m895\u001b[0m - \u001b[1mCreating dataset `mnist-temp-img-layout-v3-epoch-1`\u001b[0m\n",
      "1it [00:00,  1.63it/s]\n",
      "\u001b[32m2025-05-11 13:38:16.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_add_data\u001b[0m:\u001b[36m1702\u001b[0m - \u001b[1mUpload succeeded.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added data to mnist_temp_img_layout_v3_epoch_1. Creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 13:38:17.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36mcreate_index\u001b[0m:\u001b[36m1289\u001b[0m - \u001b[1mCreated map `0196c06d-1669-6e6c-004c-73a8c8d40e1a` in dataset `nomic/mnist-temp-img-layout-v3-epoch-1`: https://atlas.nomic.ai/data/nomic/mnist-temp-img-layout-v3-epoch-1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for projection acfbfda4-3191-4c6d-87ff-b7fbcf2b4e3f to complete. Current status: Building Map\n",
      "Projection acfbfda4-3191-4c6d-87ff-b7fbcf2b4e3f completed in 61.50 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 13:39:19.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36m_download_projected\u001b[0m:\u001b[36m538\u001b[0m - \u001b[1mDownloading projected embeddings\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00, 1926.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 505.34it/s]\n",
      "\u001b[32m2025-05-11 13:39:21.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36mtb\u001b[0m:\u001b[36m479\u001b[0m - \u001b[1mLoading projected embeddings\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00, 188.04it/s]\n",
      "\u001b[32m2025-05-11 13:39:21.909\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36mdf\u001b[0m:\u001b[36m923\u001b[0m - \u001b[33m\u001b[1mConverting to pandas dataframe. This may materialize a large amount of data into memory.\u001b[0m\n",
      "\u001b[32m2025-05-11 13:39:21.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36m_download_data\u001b[0m:\u001b[36m902\u001b[0m - \u001b[1mDownloading data\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00, 829.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 639.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1782.53it/s]\n",
      "\u001b[32m2025-05-11 13:39:22.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m872\u001b[0m - \u001b[1mLoading data\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00, 199.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 100 projected coordinates for epoch 1.\n",
      "DataFrame rows in temp map: 100. Metadata items for this epoch: 100.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 13:39:22.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36mdelete\u001b[0m:\u001b[36m833\u001b[0m - \u001b[1mDeleting dataset `mnist-temp-img-layout-v3-epoch-1` from organization `nomic`\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 UMAP processing complete. Added 100 points with positions and images.\n",
      "Deleting temporary dataset: mnist_temp_img_layout_v3_epoch_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 13:39:23.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36mdelete\u001b[0m:\u001b[36m833\u001b[0m - \u001b[1mDeleting dataset `mnist-temp-img-layout-v3-epoch-1` from organization `nomic`\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporary dataset mnist_temp_img_layout_v3_epoch_1 deleted.\n",
      "--- Starting Epoch 3/3 ---\n",
      "  Epoch [3/3], Batch [200/469], Avg Loss: 0.0247\n",
      "  Epoch [3/3], Batch [400/469], Avg Loss: 0.0284\n",
      "Epoch 3 training finished in 4.99s.\n",
      "\n",
      "Collected 100 raw embeddings and images for epoch 2.\n",
      "Creating temporary Atlas dataset: mnist_temp_img_layout_v3_epoch_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 13:39:29.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m867\u001b[0m - \u001b[1mOrganization name: `nomic`\u001b[0m\n",
      "\u001b[32m2025-05-11 13:39:30.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m895\u001b[0m - \u001b[1mCreating dataset `mnist-temp-img-layout-v3-epoch-2`\u001b[0m\n",
      "1it [00:00,  1.40it/s]\n",
      "\u001b[32m2025-05-11 13:39:31.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_add_data\u001b[0m:\u001b[36m1702\u001b[0m - \u001b[1mUpload succeeded.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added data to mnist_temp_img_layout_v3_epoch_2. Creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 13:39:32.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36mcreate_index\u001b[0m:\u001b[36m1289\u001b[0m - \u001b[1mCreated map `0196c06e-3be4-5e9c-843f-2564c0a3ee91` in dataset `nomic/mnist-temp-img-layout-v3-epoch-2`: https://atlas.nomic.ai/data/nomic/mnist-temp-img-layout-v3-epoch-2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for projection 54e24bb8-a05c-4d8f-88bd-e5909f251040 to complete. Current status: Building Map\n",
      "Projection 54e24bb8-a05c-4d8f-88bd-e5909f251040 completed in 61.60 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 13:40:34.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36m_download_projected\u001b[0m:\u001b[36m538\u001b[0m - \u001b[1mDownloading projected embeddings\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00, 2097.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1052.52it/s]\n",
      "\u001b[32m2025-05-11 13:40:36.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36mtb\u001b[0m:\u001b[36m479\u001b[0m - \u001b[1mLoading projected embeddings\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00, 160.39it/s]\n",
      "\u001b[32m2025-05-11 13:40:37.039\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36mdf\u001b[0m:\u001b[36m923\u001b[0m - \u001b[33m\u001b[1mConverting to pandas dataframe. This may materialize a large amount of data into memory.\u001b[0m\n",
      "\u001b[32m2025-05-11 13:40:37.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36m_download_data\u001b[0m:\u001b[36m902\u001b[0m - \u001b[1mDownloading data\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00, 1584.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2066.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4718.00it/s]\n",
      "\u001b[32m2025-05-11 13:40:37.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m872\u001b[0m - \u001b[1mLoading data\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00, 564.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 100 projected coordinates for epoch 2.\n",
      "DataFrame rows in temp map: 100. Metadata items for this epoch: 100.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 13:40:38.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36mdelete\u001b[0m:\u001b[36m833\u001b[0m - \u001b[1mDeleting dataset `mnist-temp-img-layout-v3-epoch-2` from organization `nomic`\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 UMAP processing complete. Added 100 points with positions and images.\n",
      "Deleting temporary dataset: mnist_temp_img_layout_v3_epoch_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 13:40:38.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36mdelete\u001b[0m:\u001b[36m833\u001b[0m - \u001b[1mDeleting dataset `mnist-temp-img-layout-v3-epoch-2` from organization `nomic`\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporary dataset mnist_temp_img_layout_v3_epoch_2 deleted.\n",
      "--- Starting Final Atlas Dataset Creation ---\n",
      "Total embeddings collected: (300, 64)\n",
      "Total metadata entries: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 13:40:39.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m867\u001b[0m - \u001b[1mOrganization name: `nomic`\u001b[0m\n",
      "\u001b[32m2025-05-11 13:40:40.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m895\u001b[0m - \u001b[1mCreating dataset `mnist-epoch-layouts-with-images-v3-final`\u001b[0m\n",
      "1it [00:00,  1.69it/s]\n",
      "\u001b[32m2025-05-11 13:40:40.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_add_data\u001b[0m:\u001b[36m1702\u001b[0m - \u001b[1mUpload succeeded.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data added to final Atlas dataset: mnist_epoch_layouts_with_images_v3. Creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 13:40:42.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36mcreate_index\u001b[0m:\u001b[36m1289\u001b[0m - \u001b[1mCreated map `0196c06f-4b3d-16f2-1ef2-dc045965739f` in dataset `nomic/mnist-epoch-layouts-with-images-v3-final`: https://atlas.nomic.ai/data/nomic/mnist-epoch-layouts-with-images-v3-final\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for projection c47c16f8-d101-4de8-8572-545e4098e356 to complete. Current status: Building Map\n",
      "Projection c47c16f8-d101-4de8-8572-545e4098e356 completed in 61.73 seconds.\n",
      "Total script execution time: 290.96s\n",
      "Script finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overall_start_time = time.time()\n",
    "# --- 4. Training Loop & Epoch-wise Atlas Processing ---\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_start_time = time.time()\n",
    "    print(f\"--- Starting Epoch {epoch+1}/{NUM_EPOCHS} ---\")\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data_batch, target_batch) in enumerate(train_loader):\n",
    "        data_batch, target_batch = data_batch.to(device), target_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(data_batch)\n",
    "        loss = criterion(outputs, target_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if (batch_idx + 1) % 200 == 0:\n",
    "            print(f'  Epoch [{epoch+1}/{NUM_EPOCHS}], Batch [{batch_idx+1}/{len(train_loader)}], Avg Loss: {running_loss / 200:.4f}')\n",
    "            running_loss = 0.0\n",
    "    print(f\"Epoch {epoch+1} training finished in {time.time() - epoch_start_time:.2f}s.\\n\")\n",
    "\n",
    "    model.eval()\n",
    "    current_epoch_raw_embeddings_list = []\n",
    "    current_epoch_metadata_list_raw = [] # This list will hold dicts with the original 'id'\n",
    "    vis_samples_collected_this_epoch = 0\n",
    "    image_offset_in_vis_subset = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_images_normalized, batch_target_labels in test_loader_for_vis:\n",
    "            batch_images_normalized_dev = batch_images_normalized.to(device)\n",
    "            _, embeddings_batch = model(batch_images_normalized_dev)\n",
    "\n",
    "            for i in range(embeddings_batch.size(0)):\n",
    "                original_idx_in_subset = image_offset_in_vis_subset + i\n",
    "                if original_idx_in_subset >= NUM_VIS_SAMPLES: continue\n",
    "\n",
    "                img_tensor_normalized = batch_images_normalized[i] # Shape (C, H, W), e.g. (1, 28, 28)\n",
    "                C = img_tensor_normalized.shape[0]\n",
    "\n",
    "                std_tensor = torch.tensor(mnist_std, device=img_tensor_normalized.device, dtype=img_tensor_normalized.dtype).view(C, 1, 1)\n",
    "                mean_tensor = torch.tensor(mnist_mean, device=img_tensor_normalized.device, dtype=img_tensor_normalized.dtype).view(C, 1, 1)\n",
    "                \n",
    "                img_tensor_denorm = img_tensor_normalized * std_tensor + mean_tensor\n",
    "                img_tensor_clamped = torch.clamp(img_tensor_denorm, 0, 1)\n",
    "                \n",
    "                # Squeeze the channel dimension IF it's 1, for ToPILImage.\n",
    "                pil_img_input_tensor = img_tensor_clamped.cpu()\n",
    "                if pil_img_input_tensor.shape[0] == 1:\n",
    "                    pil_img_input_tensor = pil_img_input_tensor.squeeze(0)\n",
    "                \n",
    "                pil_img = transforms.ToPILImage()(pil_img_input_tensor)\n",
    "                html_tag = pil_to_img_tag(pil_img, format=\"PNG\")\n",
    "\n",
    "                current_epoch_raw_embeddings_list.append(embeddings_batch[i].cpu().numpy())\n",
    "                current_epoch_metadata_list_raw.append({\n",
    "                    'id': f'vis_img_{original_idx_in_subset}_epoch_{epoch}', # Original, detailed ID\n",
    "                    'epoch': epoch,\n",
    "                    'label': batch_target_labels[i].item(),\n",
    "                    'vis_sample_idx': original_idx_in_subset,\n",
    "                    'image_display_html': html_tag\n",
    "                })\n",
    "                vis_samples_collected_this_epoch += 1\n",
    "            image_offset_in_vis_subset += embeddings_batch.size(0)\n",
    "            if vis_samples_collected_this_epoch >= NUM_VIS_SAMPLES: break\n",
    "    \n",
    "    if not current_epoch_raw_embeddings_list:\n",
    "        print(f\"No embeddings collected for epoch {epoch}. Skipping Atlas processing.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Collected {len(current_epoch_raw_embeddings_list)} raw embeddings and images for epoch {epoch}.\")\n",
    "    current_epoch_embeddings_np = np.array(current_epoch_raw_embeddings_list)\n",
    "\n",
    "    temp_dataset_name = f\"{TEMP_DATASET_PREFIX}_epoch_{epoch}\"\n",
    "    print(f\"Creating temporary Atlas dataset: {temp_dataset_name}\")\n",
    "    temp_dataset = None\n",
    "    try:\n",
    "        temp_dataset = AtlasDataset(temp_dataset_name, unique_id_field='id')\n",
    "        temp_dataset.add_data(data=current_epoch_metadata_list_raw, embeddings=current_epoch_embeddings_np)\n",
    "        print(f\"Added data to {temp_dataset_name}. Creating index...\")\n",
    "        current_projection = temp_dataset.create_index(projection='umap', topic_model=False)\n",
    "        _wait_for_projection_completion(current_projection)\n",
    "\n",
    "        atlas_map_for_current_epoch = temp_dataset.maps[0]\n",
    "        projected_coords_current_epoch = atlas_map_for_current_epoch.embeddings.projected\n",
    "        map_data_df = atlas_map_for_current_epoch.data.df\n",
    "        \n",
    "        # Generate sequential string IDs for dictionary keys, as per user's modification\n",
    "        ids_for_dict_keys = [str(i) for i in range(len(map_data_df))]\n",
    "        \n",
    "        print(f\"Retrieved {projected_coords_current_epoch.shape[0]} projected coordinates for epoch {epoch}.\")\n",
    "        print(f\"DataFrame rows in temp map: {len(map_data_df)}. Metadata items for this epoch: {len(current_epoch_metadata_list_raw)}.\")\n",
    "\n",
    "        id_to_projected_coords = {key: coords for key, coords in zip(ids_for_dict_keys, projected_coords_current_epoch)}\n",
    "\n",
    "        current_epoch_metadata_with_positions = []\n",
    "        \n",
    "        # Crucial Assumption: The order of current_epoch_metadata_list_raw, map_data_df rows, \n",
    "        # and projected_coords_current_epoch is THE SAME.\n",
    "        if len(current_epoch_metadata_list_raw) != len(map_data_df) or len(map_data_df) != projected_coords_current_epoch.shape[0]:\n",
    "            print(f\"  WARNING: Mismatch in data lengths for epoch {epoch}!\")\n",
    "            print(f\"    Metadata list: {len(current_epoch_metadata_list_raw)}, DataFrame rows: {len(map_data_df)}, Projected coords: {projected_coords_current_epoch.shape[0]}\")\n",
    "            # Fallback or error handling might be needed here if lengths don't match.\n",
    "            # For now, we proceed cautiously, iterating up to the minimum found length.\n",
    "            min_len = min(len(current_epoch_metadata_list_raw), len(map_data_df), projected_coords_current_epoch.shape[0])\n",
    "        else:\n",
    "            min_len = len(current_epoch_metadata_list_raw)\n",
    "\n",
    "        for idx in range(min_len):\n",
    "            item_meta_raw = current_epoch_metadata_list_raw[idx]\n",
    "            # Get the corresponding DataFrame row by its index\n",
    "            # (we're assuming rows in projected_coords_current_epoch align with metadata)\n",
    "            if idx < len(projected_coords_current_epoch):\n",
    "                row = projected_coords_current_epoch.iloc[idx]\n",
    "                \n",
    "                item_with_pos = item_meta_raw.copy()\n",
    "                # Access 'x' and 'y' columns properly\n",
    "                item_with_pos['Position_X'] = float(row['x'])\n",
    "                item_with_pos['Position_Y'] = float(row['y'])\n",
    "                current_epoch_metadata_with_positions.append(item_with_pos)\n",
    "            else:\n",
    "                print(f\"Warning: No projected coordinates found for index {idx}\")\n",
    "        all_epoch_embeddings_collected.extend(current_epoch_raw_embeddings_list)\n",
    "        all_epoch_metadata_collected.extend(current_epoch_metadata_with_positions)\n",
    "        temp_dataset.delete()\n",
    "        print(f\"Epoch {epoch} UMAP processing complete. Added {len(current_epoch_metadata_with_positions)} points with positions and images.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during temporary Atlas processing for epoch {epoch}: {e}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "    finally:\n",
    "        try:\n",
    "            if temp_dataset is not None:\n",
    "                print(f\"Deleting temporary dataset: {temp_dataset_name}\")\n",
    "                temp_dataset.delete()\n",
    "                print(f\"Temporary dataset {temp_dataset_name} deleted.\")\n",
    "        except Exception as e_del:\n",
    "            print(f\"Error deleting temporary dataset {temp_dataset_name}: {e_del}\")\n",
    "\n",
    "# --- 5. Create Final Atlas Dataset ---\n",
    "print(f\"--- Starting Final Atlas Dataset Creation ---\")\n",
    "if not all_epoch_metadata_collected:\n",
    "    print(\"No data collected. Skipping final Atlas dataset creation.\")\n",
    "else:\n",
    "    final_embeddings_np = np.array(all_epoch_embeddings_collected)\n",
    "    print(f\"Total embeddings collected: {final_embeddings_np.shape}\")\n",
    "    print(f\"Total metadata entries: {len(all_epoch_metadata_collected)}\")\n",
    "\n",
    "    try:\n",
    "        final_dataset = AtlasDataset(MAIN_ATLAS_DATASET_NAME+\"_final\", unique_id_field='id')\n",
    "        final_dataset.add_data(data=all_epoch_metadata_collected, embeddings=final_embeddings_np)\n",
    "        print(f\"Data added to final Atlas dataset: {MAIN_ATLAS_DATASET_NAME}. Creating index...\")\n",
    "        \n",
    "        final_project = final_dataset.create_index(projection='umap', topic_model=False) \n",
    "        _wait_for_projection_completion(final_project)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during final Atlas dataset creation: {e}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "total_script_time = time.time() - overall_start_time\n",
    "print(f\"Total script execution time: {total_script_time:.2f}s\")\n",
    "print(\"Script finished.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COORDINATE INSPECTION ===\n",
      "Type of projection data: <class 'pandas.core.frame.DataFrame'>\n",
      "Shape: (100, 3)\n",
      "Columns: ['id', 'x', 'y']\n",
      "\n",
      "First few rows:\n",
      "                   id         x         y\n",
      "0   vis_img_0_epoch_0 -0.858286  4.219957\n",
      "1  vis_img_89_epoch_0  2.598948  4.375728\n",
      "2  vis_img_67_epoch_0  5.923760  0.259158\n",
      "\n",
      "Checking for non-numeric values...\n",
      "Column 'id' has 100 non-numeric values:\n",
      "                    id         x         y\n",
      "0    vis_img_0_epoch_0 -0.858286  4.219957\n",
      "1   vis_img_89_epoch_0  2.598948  4.375728\n",
      "2   vis_img_67_epoch_0  5.923760  0.259158\n",
      "3   vis_img_29_epoch_0  2.592642  4.233738\n",
      "4   vis_img_69_epoch_0  9.876239  6.472594\n",
      "..                 ...       ...       ...\n",
      "95   vis_img_9_epoch_0  1.447178  1.289048\n",
      "96  vis_img_12_epoch_0  1.641737  1.177720\n",
      "97  vis_img_95_epoch_0  5.982210  0.749335\n",
      "98  vis_img_52_epoch_0  7.364436  4.645103\n",
      "99  vis_img_77_epoch_0  3.891787  7.331928\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "  Row 0, value: vis_img_0_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_0_epoch_0'\n",
      "  Row 1, value: vis_img_89_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_89_epoch_0'\n",
      "  Row 2, value: vis_img_67_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_67_epoch_0'\n",
      "  Row 3, value: vis_img_29_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_29_epoch_0'\n",
      "  Row 4, value: vis_img_69_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_69_epoch_0'\n",
      "  Row 5, value: vis_img_15_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_15_epoch_0'\n",
      "  Row 6, value: vis_img_78_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_78_epoch_0'\n",
      "  Row 7, value: vis_img_63_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_63_epoch_0'\n",
      "  Row 8, value: vis_img_59_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_59_epoch_0'\n",
      "  Row 9, value: vis_img_74_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_74_epoch_0'\n",
      "  Row 10, value: vis_img_85_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_85_epoch_0'\n",
      "  Row 11, value: vis_img_2_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_2_epoch_0'\n",
      "  Row 12, value: vis_img_51_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_51_epoch_0'\n",
      "  Row 13, value: vis_img_40_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_40_epoch_0'\n",
      "  Row 14, value: vis_img_18_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_18_epoch_0'\n",
      "  Row 15, value: vis_img_16_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_16_epoch_0'\n",
      "  Row 16, value: vis_img_53_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_53_epoch_0'\n",
      "  Row 17, value: vis_img_17_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_17_epoch_0'\n",
      "  Row 18, value: vis_img_34_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_34_epoch_0'\n",
      "  Row 19, value: vis_img_14_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_14_epoch_0'\n",
      "  Row 20, value: vis_img_26_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_26_epoch_0'\n",
      "  Row 21, value: vis_img_71_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_71_epoch_0'\n",
      "  Row 22, value: vis_img_55_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_55_epoch_0'\n",
      "  Row 23, value: vis_img_94_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_94_epoch_0'\n",
      "  Row 24, value: vis_img_5_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_5_epoch_0'\n",
      "  Row 25, value: vis_img_45_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_45_epoch_0'\n",
      "  Row 26, value: vis_img_36_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_36_epoch_0'\n",
      "  Row 27, value: vis_img_1_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_1_epoch_0'\n",
      "  Row 28, value: vis_img_32_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_32_epoch_0'\n",
      "  Row 29, value: vis_img_87_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_87_epoch_0'\n",
      "  Row 30, value: vis_img_92_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_92_epoch_0'\n",
      "  Row 31, value: vis_img_82_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_82_epoch_0'\n",
      "  Row 32, value: vis_img_27_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_27_epoch_0'\n",
      "  Row 33, value: vis_img_13_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_13_epoch_0'\n",
      "  Row 34, value: vis_img_43_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_43_epoch_0'\n",
      "  Row 35, value: vis_img_10_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_10_epoch_0'\n",
      "  Row 36, value: vis_img_44_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_44_epoch_0'\n",
      "  Row 37, value: vis_img_49_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_49_epoch_0'\n",
      "  Row 38, value: vis_img_66_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_66_epoch_0'\n",
      "  Row 39, value: vis_img_30_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_30_epoch_0'\n",
      "  Row 40, value: vis_img_11_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_11_epoch_0'\n",
      "  Row 41, value: vis_img_33_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_33_epoch_0'\n",
      "  Row 42, value: vis_img_48_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_48_epoch_0'\n",
      "  Row 43, value: vis_img_79_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_79_epoch_0'\n",
      "  Row 44, value: vis_img_42_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_42_epoch_0'\n",
      "  Row 45, value: vis_img_97_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_97_epoch_0'\n",
      "  Row 46, value: vis_img_76_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_76_epoch_0'\n",
      "  Row 47, value: vis_img_20_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_20_epoch_0'\n",
      "  Row 48, value: vis_img_62_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_62_epoch_0'\n",
      "  Row 49, value: vis_img_3_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_3_epoch_0'\n",
      "  Row 50, value: vis_img_57_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_57_epoch_0'\n",
      "  Row 51, value: vis_img_4_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_4_epoch_0'\n",
      "  Row 52, value: vis_img_72_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_72_epoch_0'\n",
      "  Row 53, value: vis_img_80_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_80_epoch_0'\n",
      "  Row 54, value: vis_img_7_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_7_epoch_0'\n",
      "  Row 55, value: vis_img_73_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_73_epoch_0'\n",
      "  Row 56, value: vis_img_6_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_6_epoch_0'\n",
      "  Row 57, value: vis_img_98_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_98_epoch_0'\n",
      "  Row 58, value: vis_img_60_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_60_epoch_0'\n",
      "  Row 59, value: vis_img_83_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_83_epoch_0'\n",
      "  Row 60, value: vis_img_61_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_61_epoch_0'\n",
      "  Row 61, value: vis_img_86_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_86_epoch_0'\n",
      "  Row 62, value: vis_img_68_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_68_epoch_0'\n",
      "  Row 63, value: vis_img_28_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_28_epoch_0'\n",
      "  Row 64, value: vis_img_84_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_84_epoch_0'\n",
      "  Row 65, value: vis_img_81_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_81_epoch_0'\n",
      "  Row 66, value: vis_img_37_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_37_epoch_0'\n",
      "  Row 67, value: vis_img_91_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_91_epoch_0'\n",
      "  Row 68, value: vis_img_41_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_41_epoch_0'\n",
      "  Row 69, value: vis_img_93_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_93_epoch_0'\n",
      "  Row 70, value: vis_img_75_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_75_epoch_0'\n",
      "  Row 71, value: vis_img_70_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_70_epoch_0'\n",
      "  Row 72, value: vis_img_47_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_47_epoch_0'\n",
      "  Row 73, value: vis_img_90_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_90_epoch_0'\n",
      "  Row 74, value: vis_img_31_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_31_epoch_0'\n",
      "  Row 75, value: vis_img_22_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_22_epoch_0'\n",
      "  Row 76, value: vis_img_96_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_96_epoch_0'\n",
      "  Row 77, value: vis_img_64_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_64_epoch_0'\n",
      "  Row 78, value: vis_img_8_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_8_epoch_0'\n",
      "  Row 79, value: vis_img_24_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_24_epoch_0'\n",
      "  Row 80, value: vis_img_54_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_54_epoch_0'\n",
      "  Row 81, value: vis_img_99_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_99_epoch_0'\n",
      "  Row 82, value: vis_img_56_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_56_epoch_0'\n",
      "  Row 83, value: vis_img_25_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_25_epoch_0'\n",
      "  Row 84, value: vis_img_19_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_19_epoch_0'\n",
      "  Row 85, value: vis_img_46_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_46_epoch_0'\n",
      "  Row 86, value: vis_img_65_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_65_epoch_0'\n",
      "  Row 87, value: vis_img_88_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_88_epoch_0'\n",
      "  Row 88, value: vis_img_21_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_21_epoch_0'\n",
      "  Row 89, value: vis_img_50_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_50_epoch_0'\n",
      "  Row 90, value: vis_img_38_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_38_epoch_0'\n",
      "  Row 91, value: vis_img_39_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_39_epoch_0'\n",
      "  Row 92, value: vis_img_58_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_58_epoch_0'\n",
      "  Row 93, value: vis_img_23_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_23_epoch_0'\n",
      "  Row 94, value: vis_img_35_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_35_epoch_0'\n",
      "  Row 95, value: vis_img_9_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_9_epoch_0'\n",
      "  Row 96, value: vis_img_12_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_12_epoch_0'\n",
      "  Row 97, value: vis_img_95_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_95_epoch_0'\n",
      "  Row 98, value: vis_img_52_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_52_epoch_0'\n",
      "  Row 99, value: vis_img_77_epoch_0 (type: <class 'str'>)\n",
      "    CANNOT convert to float: could not convert string to float: 'vis_img_77_epoch_0'\n",
      "\n",
      "Direct dictionary representation (first part):\n",
      "  Key: id, Value: 0      vis_img_0_epoch_0\n",
      "1     vis_img_89_epoch_0\n",
      "2     vis_img_67_epoch_0\n",
      "3     vis_img_29_epoch_0\n",
      "4     vis_img_69_epoch_0\n",
      "             ...        \n",
      "95     vis_img_9_epoch_0\n",
      "96    vis_img_12_epoch_0\n",
      "97    vis_img_95_epoch_0\n",
      "98    vis_img_52_epoch_0\n",
      "99    vis_img_77_epoch_0\n",
      "Name: id, Length: 100, dtype: object\n",
      "  Key: x, Value: 0    -0.858286\n",
      "1     2.598948\n",
      "2     5.923760\n",
      "3     2.592642\n",
      "4     9.876239\n",
      "        ...   \n",
      "95    1.447178\n",
      "96    1.641737\n",
      "97    5.982210\n",
      "98    7.364436\n",
      "99    3.891787\n",
      "Name: x, Length: 100, dtype: float32\n",
      "  Key: y, Value: 0     4.219957\n",
      "1     4.375728\n",
      "2     0.259158\n",
      "3     4.233738\n",
      "4     6.472594\n",
      "        ...   \n",
      "95    1.289048\n",
      "96    1.177720\n",
      "97    0.749335\n",
      "98    4.645103\n",
      "99    7.331928\n",
      "Name: y, Length: 100, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# Test cell to diagnose coordinate format issues\n",
    "def inspect_coordinates(projected_coords, num_samples=10):\n",
    "    print(\"=== COORDINATE INSPECTION ===\")\n",
    "    print(f\"Type of projection data: {type(projected_coords)}\")\n",
    "    \n",
    "    # Handle different data types appropriately\n",
    "    if isinstance(projected_coords, pd.DataFrame):\n",
    "        print(f\"Shape: {projected_coords.shape}\")\n",
    "        print(f\"Columns: {projected_coords.columns.tolist()}\")\n",
    "        print(\"\\nFirst few rows:\")\n",
    "        print(projected_coords.head(3))\n",
    "        \n",
    "        # Try to find problematic values in the DataFrame\n",
    "        print(\"\\nChecking for non-numeric values...\")\n",
    "        for col in projected_coords.columns:\n",
    "            non_numeric = projected_coords[col].map(lambda x: not isinstance(x, (int, float)) and not pd.isna(x))\n",
    "            if non_numeric.any():\n",
    "                problem_rows = projected_coords[non_numeric]\n",
    "                print(f\"Column '{col}' has {non_numeric.sum()} non-numeric values:\")\n",
    "                print(problem_rows)\n",
    "                \n",
    "                # Print sample of problematic values\n",
    "                for idx, val in problem_rows[col].items():\n",
    "                    print(f\"  Row {idx}, value: {val} (type: {type(val)})\")\n",
    "                    try:\n",
    "                        float_val = float(val)\n",
    "                        print(f\"    Can convert to float: {float_val}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"    CANNOT convert to float: {e}\")\n",
    "        \n",
    "    else:\n",
    "        # For numpy array, list, etc.\n",
    "        if hasattr(projected_coords, 'shape'):\n",
    "            print(f\"Shape: {projected_coords.shape}\")\n",
    "        elif hasattr(projected_coords, '__len__'):\n",
    "            print(f\"Length: {len(projected_coords)}\")\n",
    "        \n",
    "        # Try to inspect the first few items\n",
    "        print(\"\\nSample coordinates:\")\n",
    "        try:\n",
    "            sample_count = min(3, len(projected_coords) if hasattr(projected_coords, '__len__') else 0)\n",
    "            for i in range(sample_count):\n",
    "                print(f\"\\nItem {i}:\")\n",
    "                coord = projected_coords[i]\n",
    "                print(f\"  Value: {coord}\")\n",
    "                print(f\"  Type: {type(coord)}\")\n",
    "                \n",
    "                # If it's an array-like object itself\n",
    "                if hasattr(coord, '__len__') and not isinstance(coord, str):\n",
    "                    for j, comp in enumerate(coord):\n",
    "                        print(f\"    Component {j}: {comp} (type: {type(comp)})\")\n",
    "                        try:\n",
    "                            float_val = float(comp)\n",
    "                            print(f\"      Converts to float: {float_val}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"      CANNOT convert to float: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error inspecting items: {e}\")\n",
    "    \n",
    "    # Direct access to see what's actually there\n",
    "    print(\"\\nDirect dictionary representation (first part):\")\n",
    "    try:\n",
    "        if hasattr(projected_coords, 'items'):  # For dict-like objects\n",
    "            for i, (k, v) in enumerate(projected_coords.items()):\n",
    "                if i >= 3: break\n",
    "                print(f\"  Key: {k}, Value: {v}\")\n",
    "        elif hasattr(projected_coords, '__dict__'):  # For custom objects\n",
    "            print(f\"  Attributes: {list(projected_coords.__dict__.keys())}\")\n",
    "        else:\n",
    "            print(f\"  Raw representation: {str(projected_coords)[:300]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with direct representation: {e}\")\n",
    "\n",
    "# Place this immediately after retrieving projected_coords_current_epoch\n",
    "inspect_coordinates(projected_coords_current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
