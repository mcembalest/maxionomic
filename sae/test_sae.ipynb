{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4d9bcd1-acfd-4643-af96-854c54bd4326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triton not installed, using eager implementation of SAE decoder.\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import Dict\n",
    "\n",
    "from nomic.atlas import AtlasDataset\n",
    "from latentsae import Sae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff1d7448-daa0-4c03-bbe6-594dda518572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e69071cab0459f8445fd2703525e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dropping extra args {'signed': False}\n"
     ]
    }
   ],
   "source": [
    "sae_model = Sae.load_from_hub(\"enjalot/sae-nomic-text-v1.5-FineWeb-edu-100BT\", \"64_32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b86fee8b-77c5-4090-af12-44fda4ccc958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "emb_model = SentenceTransformer(\"nomic-ai/nomic-embed-text-v1.5\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0338c9d3-a05c-4de0-b64d-3b4f5d39ce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\"\n",
    "sae_model = sae_model.to(device)\n",
    "emb_model = emb_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811b537c",
   "metadata": {},
   "source": [
    "# Test the SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82a2eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_features = pd.read_parquet(\"features.parquet\").to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46e5e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_encoder_output(encoder_output, k: int = 5) -> Dict[int, float]:\n",
    "    total_activations = {}\n",
    "    for idx, act in zip(encoder_output.top_indices.cpu().flatten(), encoder_output.top_acts.cpu().flatten()):\n",
    "        idx_int = idx.item()\n",
    "        if idx_int in total_activations:\n",
    "            total_activations[idx_int] += act.item()\n",
    "        else:\n",
    "            total_activations[idx_int] = act.item()\n",
    "    sorted_activations = dict(sorted(total_activations.items(), key=lambda item: item[1], reverse=True))\n",
    "    return sorted_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "188ea584-3584-42df-8a46-729f69546d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderOutput(top_acts=tensor([[10.2676,  9.1370,  6.9692,  6.5758,  6.5321,  6.4380,  6.0169,  5.9566,\n",
       "          5.9451,  5.8986,  5.8974,  5.8676,  5.8553,  5.8119,  5.7983,  5.7916,\n",
       "          5.7621,  5.7501,  5.7412,  5.7339,  5.7236,  5.6925,  5.6840,  5.6580,\n",
       "          5.6326,  5.6273,  5.6240,  5.5846,  5.5812,  5.5757,  5.5744,  5.5702,\n",
       "          5.5594,  5.4869,  5.4468,  5.4023,  5.3949,  5.3904,  5.3837,  5.3410,\n",
       "          5.3271,  5.3213,  5.3161,  5.3132,  5.3039,  5.2932,  5.2801,  5.2531,\n",
       "          5.2474,  5.2139,  5.2120,  5.2048,  5.1769,  5.1763,  5.1713,  5.1688,\n",
       "          5.1683,  5.1613,  5.1479,  5.1476,  5.1438,  5.1357,  5.1347,  5.1287]],\n",
       "       device='mps:0', grad_fn=<TopkBackward0>), top_indices=tensor([[19159, 16718,  6328, 20182,  1239,  6939, 23114, 11704, 11465, 23945,\n",
       "          6625,  4997,  1741,  2884, 16833, 22050, 17685, 11466,  9254,  7775,\n",
       "         16983,  2910,  4080,   433, 13437,  1865, 21547,  3104,  3123,  7919,\n",
       "          9995, 18136,   193, 10103,   960,  6966, 12237, 10317,  6883,  9732,\n",
       "          3303,  4637, 18348, 10142,  2960, 14644, 20602, 16449,  2381,  5959,\n",
       "          9434,  6308, 23651, 21953, 11020, 11930, 16434, 12011,  7743,  7162,\n",
       "          9094, 22808,  8830, 10696]], device='mps:0'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_model.encode(emb_model.encode(['ben'], convert_to_tensor=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46f52ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_encoder_output(sorted_activations, k=5):\n",
    "    return [loaded_features[idx]['label'] for idx in list(islice(sorted_activations, k))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4081cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strings = ['UMAP', 't-SNE', 'PCA', 'SVD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9502e109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cultural narratives and storytelling techniques',\n",
       " 'advanced materials and manufacturing processes',\n",
       " 'quantum computing and nanomaterial advancements',\n",
       " 'taser usage and technology in law enforcement',\n",
       " 'astrophysics and materials science advancements']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_encoder_output(aggregate_encoder_output(sae_model.encode(emb_model.encode(test_strings, convert_to_tensor=True))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6cbaa0-e85f-4654-b013-fefc5b1403d2",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "gpt4o-mini overuses the words \"interdisciplinary\" and \"quantum\"\n",
    "\n",
    "Manual nomencodes\n",
    "\n",
    "5507: Apple, Inc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a5c99",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112119ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
