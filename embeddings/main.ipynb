{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "I want to compare embedding models for their scores on a small quantitative benchmark, as well as visually on a new custom qualitative benchmark\n",
    "\n",
    "## Models\n",
    "\n",
    "- sentence-transformers/all-MiniLM-L6-v2\n",
    "- sentence-transformers/all-mpnet-base-v2\n",
    "- nomic-ai/nomic-embed-text-v1\n",
    "- nomic-ai/nomic-embed-text-v1.5\n",
    "- nomic-ai/modernbert-embed-base\n",
    "- lightonai/modernbert-embed-large\n",
    "- dunzhang/stella_en_400M_v5\n",
    "- mixedbread-ai/mxbai-embed-large-v1\n",
    "- jinaai/jina-embeddings-v3\n",
    "- Snowflake/snowflake-arctic-embed-l-v2.0\n",
    "- ibm-granite/granite-embedding-278m-multilingual\n",
    "- BAAI/bge-m3\n",
    "- Alibaba-NLP/gte-multilingual-base\n",
    "- intfloat/e5-base-v2\n",
    "- intfloat/e5-large-v2\n",
    "- answerdotai/answerai-colbert-small-v1\n",
    "- jxm/cde-small-v1\n",
    "- jxm/cde-small-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"nomic-ai/nomic-embed-text-v1\",\n",
    "    \"nomic-ai/nomic-embed-text-v1.5\", \n",
    "    \"nomic-ai/modernbert-embed-base\",\n",
    "    \"lightonai/modernbert-embed-large\",\n",
    "    \"dunzhang/stella_en_400M_v5\",\n",
    "    \"mixedbread-ai/mxbai-embed-large-v1\",\n",
    "    \"jinaai/jina-embeddings-v3\",\n",
    "    \"Snowflake/snowflake-arctic-embed-l-v2.0\",\n",
    "    \"ibm-granite/granite-embedding-278m-multilingual\",\n",
    "    \"BAAI/bge-m3\",\n",
    "    \"Alibaba-NLP/gte-multilingual-base\",\n",
    "    \"intfloat/e5-base-v2\",\n",
    "    \"intfloat/e5-large-v2\",\n",
    "    \"answerdotai/answerai-colbert-small-v1\",\n",
    "    \"jxm/cde-small-v1\",\n",
    "    \"jxm/cde-small-v2\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "d0_corpus = load_dataset(\"zeta-alpha-ai/NanoTouche2020\", \"corpus\")[\"train\"]\n",
    "d0_qrels = load_dataset(\"zeta-alpha-ai/NanoTouche2020\", \"qrels\")[\"train\"]\n",
    "d0_queries = load_dataset(\"zeta-alpha-ai/NanoTouche2020\", \"queries\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from query ID to relevant corpus IDs\n",
    "qrels_dict = {}\n",
    "for sample in d0_qrels:\n",
    "    query_id = sample['query-id']\n",
    "    if query_id not in qrels_dict:\n",
    "        qrels_dict[query_id] = set()\n",
    "    qrels_dict[query_id].add(sample['corpus-id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_allminilml6v2 = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode all corpus texts\n",
    "query_embeddings = model_allminilml6v2.encode(d0_queries['text'])\n",
    "corpus_embeddings = model_allminilml6v2.encode(d0_corpus['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert embeddings to torch tensors\n",
    "query_embeddings_tensor = torch.tensor(query_embeddings)\n",
    "corpus_embeddings_tensor = torch.tensor(corpus_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG@10: 0.7310\n",
      "Average Recall@10: 0.2819\n"
     ]
    }
   ],
   "source": [
    "# Calculate scores and metrics\n",
    "ndcg_scores = []\n",
    "recall_at_k_scores = []\n",
    "k = 10\n",
    "\n",
    "for idx, query_embedding in enumerate(query_embeddings):\n",
    "    # Calculate cosine similarities using cos_sim\n",
    "    similarities = cos_sim(\n",
    "        query_embeddings_tensor[idx:idx+1], \n",
    "        corpus_embeddings_tensor\n",
    "    ).squeeze()\n",
    "    \n",
    "    # Get top k document indices (make sure k is not larger than corpus size)\n",
    "    k_actual = min(k, len(corpus_embeddings))\n",
    "    top_k_indices = torch.topk(similarities, k=k_actual).indices.tolist()\n",
    "    \n",
    "    # Get relevant docs for this query\n",
    "    query_id = d0_queries[idx]['_id']\n",
    "    relevant_docs = qrels_dict.get(query_id, set())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    retrieved_relevant = [1 if d0_corpus[i]['_id'] in relevant_docs else 0 for i in top_k_indices]\n",
    "    \n",
    "    # Calculate NDCG@k\n",
    "    dcg = sum((rel / np.log2(rank + 2)) for rank, rel in enumerate(retrieved_relevant))\n",
    "    ideal_rel = sorted(retrieved_relevant, reverse=True)\n",
    "    idcg = sum((rel / np.log2(rank + 2)) for rank, rel in enumerate(ideal_rel))\n",
    "    ndcg = dcg / idcg if idcg > 0 else 0\n",
    "    ndcg_scores.append(ndcg)\n",
    "    \n",
    "    # Calculate Recall@k\n",
    "    num_relevant_retrieved = sum(retrieved_relevant)\n",
    "    recall = num_relevant_retrieved / len(relevant_docs) if len(relevant_docs) > 0 else 0\n",
    "    recall_at_k_scores.append(recall)\n",
    "\n",
    "# Print results\n",
    "print(f\"Average NDCG@{k}: {np.mean(ndcg_scores):.4f}\")\n",
    "print(f\"Average Recall@{k}: {np.mean(recall_at_k_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
