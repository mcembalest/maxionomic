{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d9bcd1-acfd-4643-af96-854c54bd4326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triton not installed, using eager implementation of SAE decoder.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from typing import Dict, List, NamedTuple, Tuple, Union\n",
    "\n",
    "from nomic.atlas import AtlasDataset\n",
    "\n",
    "from latentsae import Sae\n",
    "\n",
    "import dash\n",
    "from dash import html, dcc, callback_context\n",
    "import plotly.graph_objects as go\n",
    "from dash.dependencies import Input, Output, State\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"\"\"Return the first n items of the iterable as a list.\"\"\"\n",
    "    return list(islice(iterable, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff1d7448-daa0-4c03-bbe6-594dda518572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0234fccb2a274f93bcf0a3135838187d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dropping extra args {'signed': False}\n"
     ]
    }
   ],
   "source": [
    "sae_model = Sae.load_from_hub(\"enjalot/sae-nomic-text-v1.5-FineWeb-edu-100BT\", \"64_32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b86fee8b-77c5-4090-af12-44fda4ccc958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "emb_model = SentenceTransformer(\"nomic-ai/nomic-embed-text-v1.5\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0338c9d3-a05c-4de0-b64d-3b4f5d39ce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\"\n",
    "sae_model = sae_model.to(device)\n",
    "emb_model = emb_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8db067e1-38d0-4fc8-b9b1-12acccc7e77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-20 09:34:00.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m763\u001b[0m - \u001b[1mLoading existing dataset `nomic/y-combinator`.\u001b[0m\n",
      "\u001b[32m2024-09-20 09:34:01.265\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36mdf\u001b[0m:\u001b[36m923\u001b[0m - \u001b[33m\u001b[1mConverting to pandas dataframe. This may materialize a large amount of data into memory.\u001b[0m\n",
      "\u001b[32m2024-09-20 09:34:01.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36m_download_data\u001b[0m:\u001b[36m902\u001b[0m - \u001b[1mDownloading data\u001b[0m\n",
      "100%|██████████| 5/5 [00:00<00:00, 3156.46it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 2714.06it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 3261.51it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 3508.12it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 4039.20it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 3075.45it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 4129.06it/s]\n",
      "\u001b[32m2024-09-20 09:34:01.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m872\u001b[0m - \u001b[1mLoading data\u001b[0m\n",
      "100%|██████████| 5/5 [00:00<00:00, 473.31it/s]\n",
      "\u001b[32m2024-09-20 09:34:02.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36m_download_latent\u001b[0m:\u001b[36m550\u001b[0m - \u001b[1mDownloading latent embeddings\u001b[0m\n",
      "100%|██████████| 5/5 [00:00<00:00, 1565.97it/s]\n",
      "\u001b[32m2024-09-20 09:34:02.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36mlatent\u001b[0m:\u001b[36m527\u001b[0m - \u001b[1mLoading latent embeddings\u001b[0m\n",
      "100%|██████████| 5/5 [00:00<00:00, 312.50it/s]\n",
      "\u001b[32m2024-09-20 09:34:02.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36m_download_projected\u001b[0m:\u001b[36m538\u001b[0m - \u001b[1mDownloading projected embeddings\u001b[0m\n",
      "100%|██████████| 5/5 [00:00<00:00, 1047.74it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 3881.46it/s]\n",
      "\u001b[32m2024-09-20 09:34:02.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.data_operations\u001b[0m:\u001b[36mtb\u001b[0m:\u001b[36m479\u001b[0m - \u001b[1mLoading projected embeddings\u001b[0m\n",
      "100%|██████████| 5/5 [00:00<00:00, 1028.57it/s]\n"
     ]
    }
   ],
   "source": [
    "datamap = AtlasDataset('nomic/y-combinator').maps[0]\n",
    "yc_df = datamap.data.df\n",
    "yc_embeddings = datamap.embeddings.latent\n",
    "yc_projected_embeddings = datamap.embeddings.projected\n",
    "yc_projected_embeddings['year'] = yc_df.Year\n",
    "\n",
    "selection_idx = yc_df[(yc_df.Year > 0) & (yc_df.oneliner_then_tags != \"null\")].index.values\n",
    "yc_df = yc_df.loc[selection_idx]\n",
    "yc_projected_embeddings = yc_projected_embeddings.loc[selection_idx]\n",
    "years = sorted(yc_projected_embeddings['year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c557d14-76b2-422d-9c39-78f9925a746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_features = pd.read_parquet(\"sae/features.parquet\").to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cecff650-cd41-4b81-8d86-9ad5e0474e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderOutput(NamedTuple):\n",
    "    top_acts: torch.Tensor\n",
    "    top_indices: torch.Tensor\n",
    "\n",
    "def aggregate_encoder_output(encoder_output: EncoderOutput) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Aggregates an encoder output over the batch dimension and sums the total activation\n",
    "    for each unique index in top_indices.\n",
    "\n",
    "    Args:\n",
    "    encoder_output (EncoderOutput): A named tuple containing top_acts and top_indices tensors.\n",
    "\n",
    "    Returns:\n",
    "    Dict[int, float]: A dictionary mapping indices to their total activation values.\n",
    "    \"\"\"\n",
    "    # Move tensors to CPU for easier processing\n",
    "    top_acts = encoder_output.top_acts.cpu()\n",
    "    top_indices = encoder_output.top_indices.cpu()\n",
    "\n",
    "    # Flatten the tensors\n",
    "    flat_acts = top_acts.flatten()\n",
    "    flat_indices = top_indices.flatten()\n",
    "\n",
    "    # Create a dictionary to store the aggregated values\n",
    "    aggregated = {}\n",
    "\n",
    "    # Iterate through the flattened tensors\n",
    "    for idx, act in zip(flat_indices, flat_acts):\n",
    "        idx_int = idx.item()  # Convert tensor to Python int\n",
    "        if idx_int in aggregated:\n",
    "            aggregated[idx_int] += act.item()\n",
    "        else:\n",
    "            aggregated[idx_int] = act.item()\n",
    "\n",
    "    return dict(sorted(aggregated.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8faa14b0-2148-4eb6-baef-cb01e1d47742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n"
     ]
    }
   ],
   "source": [
    "# Precompute bar chart data for each year\n",
    "bar_chart_data = {}\n",
    "for year in years:\n",
    "    print(year)\n",
    "    s = yc_df[yc_df.Year == year].oneliner_then_tags.values\n",
    "    text_embeddings = emb_model.encode(s, convert_to_tensor=True, normalize_embeddings=True)\n",
    "    top_activated_features_sae_output = sae_model.encode(text_embeddings)\n",
    "    top_sae_features_hist = aggregate_encoder_output(top_activated_features_sae_output)\n",
    "    idx = list(top_sae_features_hist.keys())[:10]\n",
    "    names = [f'{i}: {loaded_features[i][\"label\"]}' for i in idx]\n",
    "    vals = [top_sae_features_hist[i] for i in idx]\n",
    "    bar_chart_data[year] = {'names': names, 'vals': vals}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d836dbc-1673-4e91-be87-18830d169146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x3b1375190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dash\n",
    "from dash import html, dcc\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "def create_figure(selected_year):\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Y Combinator over time\", f\"Top SAE Features for {selected_year}\"))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=yc_projected_embeddings['x'],\n",
    "        y=-yc_projected_embeddings['y'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=6,\n",
    "            color=['red' if year == selected_year else 'lightgrey' for year in yc_projected_embeddings['year']],\n",
    "            opacity=0.3\n",
    "        ),\n",
    "        text=[\n",
    "            f'{row.Company} {row.Batch} {row.Status}<br><br>{row.oneliner_then_tags}' \n",
    "            for _, row in yc_df.iterrows()\n",
    "        ],\n",
    "        hoverinfo='text'\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=bar_chart_data[selected_year]['names'],\n",
    "        y=bar_chart_data[selected_year]['vals'],\n",
    "        name='SAE Features'\n",
    "    ), row=1, col=2)\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"X\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Y\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"SAE Features\", tickangle=45, row=2, col=1, tickfont=3)\n",
    "    fig.update_yaxes(title_text=\"Activation\", row=2, col=1)\n",
    "\n",
    "    return fig\n",
    "\n",
    "# Update the app layout\n",
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "        dcc.Graph(id='main-graph', style={'height': '400px'}),\n",
    "        dcc.Slider(\n",
    "            id='year-slider',\n",
    "            min=min(years),\n",
    "            max=max(years),\n",
    "            value=min(years),\n",
    "            marks={str(year): str(year) for year in years},\n",
    "            step=None\n",
    "        )\n",
    "    ], style={'width': '100%', 'padding': '20px'})\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('main-graph', 'figure'),\n",
    "    Input('year-slider', 'value')\n",
    ")\n",
    "def update_graph(selected_year):\n",
    "    return create_figure(selected_year)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6cbaa0-e85f-4654-b013-fefc5b1403d2",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "gpt4o-mini overuses the words \"interdisciplinary\" and \"quantum\"\n",
    "\n",
    "Manual nomencodes\n",
    "\n",
    "5507: Apple, Inc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a5c99",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "811b537c",
   "metadata": {},
   "source": [
    "# Test the SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52e09911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New York City characteristics and demographics',\n",
       " 'Cultural narratives and storytelling techniques',\n",
       " 'quantum computing and nanomaterial advancements',\n",
       " 'advanced materials and manufacturing processes',\n",
       " 'John Jacob Astor and American fur trade']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x['label'] for x in np.array(loaded_features)[take(5, aggregate_encoder_output(\n",
    "    sae_model.encode(\n",
    "        emb_model.encode(\n",
    "            [\n",
    "                \"The Big Apple\", \n",
    "                \"Gotham\", \n",
    "                \"Empire State Building\", \n",
    "                \"Five Boroughs\"\n",
    "            ], \n",
    "            convert_to_tensor=True\n",
    "        )\n",
    "    )\n",
    "))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112119ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
